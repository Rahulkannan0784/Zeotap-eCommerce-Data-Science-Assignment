{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load datasets\n",
        "customers = pd.read_csv('Customers.csv')\n",
        "products = pd.read_csv('Products.csv')\n",
        "transactions = pd.read_csv('Transactions.csv')\n",
        "\n",
        "# Merge datasets\n",
        "merged_data = pd.merge(transactions, customers, on='CustomerID')\n",
        "merged_data = pd.merge(merged_data, products, on='ProductID')\n",
        "\n"
      ],
      "metadata": {
        "id": "NyyE7iXJ_6Bn"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering\n",
        "customer_profiles = merged_data.groupby('CustomerID').agg(\n",
        "    total_spending=('TotalValue', 'sum'),\n",
        "    avg_transaction_value=('TotalValue', 'mean'),\n",
        "    num_transactions=('TransactionID', 'count'),\n",
        "    favorite_category=('Category', lambda x: x.mode()[0])\n",
        ").reset_index()\n",
        "\n"
      ],
      "metadata": {
        "id": "55jmRjSLAAjv"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge with customer data\n",
        "customer_profiles = pd.merge(customer_profiles, customers, on='CustomerID')\n",
        "\n",
        "# One-hot encode 'Region'\n",
        "customer_profiles = pd.get_dummies(customer_profiles, columns=['Region'])\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = MinMaxScaler()\n",
        "numerical_features = ['total_spending', 'avg_transaction_value', 'num_transactions']\n",
        "customer_profiles[numerical_features] = scaler.fit_transform(customer_profiles[numerical_features])\n",
        "\n",
        "# Drop non-numerical columns for clustering\n",
        "X = customer_profiles.drop(columns=['CustomerID', 'CustomerName', 'SignupDate', 'favorite_category'])\n"
      ],
      "metadata": {
        "id": "Idc1GKakC6Ub"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Perform K-Means Clustering\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)  # Adjust number of clusters as needed\n",
        "customer_profiles['Cluster'] = kmeans.fit_predict(X)\n",
        "\n"
      ],
      "metadata": {
        "id": "7MSVQgWCC-lf"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find nearest neighbors within each cluster\n",
        "lookalike_map = {}\n",
        "for cluster in customer_profiles['Cluster'].unique():\n",
        "    cluster_data = customer_profiles[customer_profiles['Cluster'] == cluster]\n",
        "    cluster_ids = cluster_data['CustomerID'].values\n",
        "    cluster_features = cluster_data.drop(columns=['CustomerID', 'CustomerName', 'SignupDate', 'favorite_category', 'Cluster']).values\n",
        "\n",
        "    # Fit Nearest Neighbors model\n",
        "    nn = NearestNeighbors(n_neighbors=4, metric='euclidean')  # 4 because it includes the customer itself\n",
        "    nn.fit(cluster_features)\n",
        "\n",
        "    # Find nearest neighbors for each customer in the cluster\n",
        "    distances, indices = nn.kneighbors(cluster_features)\n",
        "    for i, customer_id in enumerate(cluster_ids):\n",
        "        if customer_id in [f'C{str(i).zfill(4)}' for i in range(1, 21)]:  # Only for first 20 customers\n",
        "            neighbor_ids = [cluster_ids[j] for j in indices[i][1:]]  # Exclude self\n",
        "            neighbor_scores = [1 / (1 + d) for d in distances[i][1:]]  # Convert distance to similarity score\n",
        "            lookalike_map[customer_id] = list(zip(neighbor_ids, neighbor_scores))\n"
      ],
      "metadata": {
        "id": "2PD1-kQjDDa8"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Sort the lookalike_map by CustomerID\n",
        "sorted_lookalike_map = {k: lookalike_map[k] for k in sorted(lookalike_map.keys())}\n",
        "\n",
        "# Convert sorted_lookalike_map to a DataFrame for better CSV formatting\n",
        "lookalike_df = pd.DataFrame.from_dict(sorted_lookalike_map, orient='index')\n",
        "lookalike_df.columns = ['Lookalike1', 'Lookalike2', 'Lookalike3']  # Rename columns\n",
        "\n",
        "# Save to CSV with column names\n",
        "lookalike_df.to_csv('Rahul_Kannan_Lookalike.csv', index=True, index_label='CustomerID')\n",
        "\n",
        "# Print results for first 20 customers in order\n",
        "for customer_id, similar_customers in sorted_lookalike_map.items():\n",
        "    print(f\"{customer_id}: {similar_customers}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzCs_q8hDGw_",
        "outputId": "e47396a9-1b81-444d-ba5b-1d14b849c8cc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C0001: [('C0137', 0.9959126526309704), ('C0152', 0.9941795833573235), ('C0107', 0.9520858336674961)]\n",
            "C0002: [('C0142', 0.9227381553764861), ('C0088', 0.9026520852250701), ('C0134', 0.8784613267418189)]\n",
            "C0003: [('C0133', 0.9658399822913127), ('C0052', 0.94983219593737), ('C0191', 0.8908775388091351)]\n",
            "C0004: [('C0113', 0.930282741787746), ('C0102', 0.9030591301959036), ('C0108', 0.8989429590094472)]\n",
            "C0005: [('C0159', 0.9892476724430751), ('C0186', 0.9279666659374441), ('C0146', 0.8963227171790878)]\n",
            "C0006: [('C0158', 0.8978962008633448), ('C0171', 0.8816734557255188), ('C0187', 0.8681787559992562)]\n",
            "C0007: [('C0140', 0.8792447396662206), ('C0092', 0.8788930693880573), ('C0193', 0.8783911724209452)]\n",
            "C0008: [('C0109', 0.8599775351124415), ('C0139', 0.8270859090113001), ('C0098', 0.8146925791092872)]\n",
            "C0009: [('C0121', 0.9011458327180681), ('C0010', 0.8586921839815093), ('C0198', 0.8563385169549942)]\n",
            "C0010: [('C0199', 0.944967079656729), ('C0111', 0.9036531286381025), ('C0103', 0.8830625758311919)]\n",
            "C0011: [('C0107', 0.9805687034190362), ('C0048', 0.9779068473671977), ('C0152', 0.9395958880954393)]\n",
            "C0012: [('C0155', 0.9786422172339257), ('C0108', 0.9460863112404982), ('C0013', 0.8972256914407419)]\n",
            "C0013: [('C0087', 0.9175280829645014), ('C0155', 0.915145108683213), ('C0012', 0.8972256914407419)]\n",
            "C0014: [('C0198', 0.8578980530453609), ('C0060', 0.8391035024259096), ('C0009', 0.8278676369614438)]\n",
            "C0015: [('C0144', 0.9425744020172503), ('C0036', 0.8874719528499716), ('C0131', 0.8799222794062929)]\n",
            "C0016: [('C0183', 0.9954996455817379), ('C0067', 0.887572674846579), ('C0125', 0.8820896385311473)]\n",
            "C0017: [('C0124', 0.9002351196992139), ('C0075', 0.869053697488677), ('C0051', 0.8181395840540654)]\n",
            "C0018: [('C0117', 0.8854640994487948), ('C0079', 0.8764353060707254), ('C0026', 0.8596617269673914)]\n",
            "C0019: [('C0172', 0.9973994894130799), ('C0111', 0.9050747599199686), ('C0103', 0.8724874317968542)]\n",
            "C0020: [('C0144', 0.8049981619996719), ('C0042', 0.7918128845409355), ('C0176', 0.7891259937524772)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Lookalike Model successfully segments customers and identifies similar ones using clustering and nearest neighbor techniques. The methodology provides a scalable and data-driven approach to enhance customer engagement, optimize marketing campaigns, and drive business growth. Future improvements can include incorporating deep learning-based similarity models or additional customer behavioral attributes for enhanced accuracy."
      ],
      "metadata": {
        "id": "kb9ZGJ0gEuTc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ABqpyFXcDVOd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}